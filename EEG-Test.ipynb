{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# EEG SSVEP Test"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d726ba570e097eb3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 一、Dataset类创建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d3b19d8623132aa4"
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-02-25T15:44:35.169340200Z",
     "start_time": "2024-02-25T15:44:35.153483200Z"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Any, Callable, Dict, List, Optional, Tuple\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import scipy\n",
    "\n",
    "class Benchmark(Dataset):\n",
    "    \n",
    "    classes = {\n",
    "        \n",
    "    }\n",
    "    \n",
    "    stim_event_freq = [8., 8.2, 8.4, 8.6, 8.8, 9., 9.2, 9.4, 9.6, 9.8, 10., 10.2, 10.4, 10.6,\n",
    "                       10.8, 11., 11.2, 11.4, 11.6, 11.8, 12., 12.2, 12.4, 12.6, 12.8, 13., 13.2, 13.4,\n",
    "                       13.6, 13.8, 14., 14.2, 14.4, 14.6, 14.8, 15., 15.2, 15.4, 15.6, 15.8]\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        root: str = '',\n",
    "        train: bool = True,\n",
    "        transform: Optional[Callable] = None,\n",
    "        target_transform: Optional[Callable] = None,\n",
    "    ) -> None:\n",
    "        super(Dataset).__init__()\n",
    "        self.root = root\n",
    "        self.train = train\n",
    "        self.transform = transform\n",
    "        self.target_transform = target_transform\n",
    "        self.data, self.pre_data, self.label = self.load_data()\n",
    "    \n",
    "    def load_data(self) -> Tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "        channels = [53, 54, 55, 57, 58, 59, 61, 62, 63]\n",
    "        channels = [i - 1 for i in channels]\n",
    "        \n",
    "        if self.train:\n",
    "            # train data\n",
    "            data = np.zeros((200*35, len(channels), 1375))\n",
    "            pre_data = np.zeros((200*35, len(channels), 125))\n",
    "            label = np.zeros(200*35, dtype=int)\n",
    "        else:\n",
    "            # test data\n",
    "            data = np.zeros((40*35, len(channels), 1375))\n",
    "            pre_data = np.zeros((40*35, len(channels), 125))\n",
    "            label = np.zeros(40*35, dtype=int)\n",
    "            \n",
    "        for sub_num in range(1, 36):\n",
    "            f = scipy.io.loadmat(self.root + f\"/S{sub_num}.mat\")\n",
    "            print(f\"mat{sub_num}文件大小: {f['data'].shape}\")\n",
    "            for block in range(6):\n",
    "                for target in range(40):\n",
    "                    if self.train and block!=5:\n",
    "                        data[(sub_num - 1) * 200 + block * 40 + target] = f[\"data\"][channels, 125:, target, block]\n",
    "                        pre_data[(sub_num - 1) * 200 + block * 40 + target] = f[\"data\"][channels, :125, target, block]\n",
    "                        label[(sub_num - 1) * 200 + block * 40 + target] = int(target + 1)\n",
    "                    elif not self.train and block==5:\n",
    "                        data[(sub_num - 1) * 40 + target] = f[\"data\"][channels, 125:, target, block]\n",
    "                        pre_data[(sub_num - 1) * 40 + target] = f[\"data\"][channels, :125, target, block]\n",
    "                        label[(sub_num - 1) * 40 + target] = int(target + 1)\n",
    "        return data, pre_data, label\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, index) -> Tuple[Any, Any]:\n",
    "        eeg, target = self.data[index], self.label[index]\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            eeg = self.transform(eeg)\n",
    "\n",
    "        if self.target_transform is not None:\n",
    "            target = self.target_transform(target)\n",
    "        \n",
    "        return eeg, target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mat1文件大小: (64, 1500, 40, 6)\n",
      "mat2文件大小: (64, 1500, 40, 6)\n",
      "mat3文件大小: (64, 1500, 40, 6)\n",
      "mat4文件大小: (64, 1500, 40, 6)\n",
      "mat5文件大小: (64, 1500, 40, 6)\n",
      "mat6文件大小: (64, 1500, 40, 6)\n",
      "mat7文件大小: (64, 1500, 40, 6)\n",
      "mat8文件大小: (64, 1500, 40, 6)\n",
      "mat9文件大小: (64, 1500, 40, 6)\n",
      "mat10文件大小: (64, 1500, 40, 6)\n",
      "mat11文件大小: (64, 1500, 40, 6)\n",
      "mat12文件大小: (64, 1500, 40, 6)\n",
      "mat13文件大小: (64, 1500, 40, 6)\n",
      "mat14文件大小: (64, 1500, 40, 6)\n",
      "mat15文件大小: (64, 1500, 40, 6)\n",
      "mat16文件大小: (64, 1500, 40, 6)\n",
      "mat17文件大小: (64, 1500, 40, 6)\n",
      "mat18文件大小: (64, 1500, 40, 6)\n",
      "mat19文件大小: (64, 1500, 40, 6)\n",
      "mat20文件大小: (64, 1500, 40, 6)\n",
      "mat21文件大小: (64, 1500, 40, 6)\n",
      "mat22文件大小: (64, 1500, 40, 6)\n",
      "mat23文件大小: (64, 1500, 40, 6)\n",
      "mat24文件大小: (64, 1500, 40, 6)\n",
      "mat25文件大小: (64, 1500, 40, 6)\n",
      "mat26文件大小: (64, 1500, 40, 6)\n",
      "mat27文件大小: (64, 1500, 40, 6)\n",
      "mat28文件大小: (64, 1500, 40, 6)\n",
      "mat29文件大小: (64, 1500, 40, 6)\n",
      "mat30文件大小: (64, 1500, 40, 6)\n",
      "mat31文件大小: (64, 1500, 40, 6)\n",
      "mat32文件大小: (64, 1500, 40, 6)\n",
      "mat33文件大小: (64, 1500, 40, 6)\n",
      "mat34文件大小: (64, 1500, 40, 6)\n",
      "mat35文件大小: (64, 1500, 40, 6)\n",
      "mat1文件大小: (64, 1500, 40, 6)\n",
      "mat2文件大小: (64, 1500, 40, 6)\n",
      "mat3文件大小: (64, 1500, 40, 6)\n",
      "mat4文件大小: (64, 1500, 40, 6)\n",
      "mat5文件大小: (64, 1500, 40, 6)\n",
      "mat6文件大小: (64, 1500, 40, 6)\n",
      "mat7文件大小: (64, 1500, 40, 6)\n",
      "mat8文件大小: (64, 1500, 40, 6)\n",
      "mat9文件大小: (64, 1500, 40, 6)\n",
      "mat10文件大小: (64, 1500, 40, 6)\n",
      "mat11文件大小: (64, 1500, 40, 6)\n",
      "mat12文件大小: (64, 1500, 40, 6)\n",
      "mat13文件大小: (64, 1500, 40, 6)\n",
      "mat14文件大小: (64, 1500, 40, 6)\n",
      "mat15文件大小: (64, 1500, 40, 6)\n",
      "mat16文件大小: (64, 1500, 40, 6)\n",
      "mat17文件大小: (64, 1500, 40, 6)\n",
      "mat18文件大小: (64, 1500, 40, 6)\n",
      "mat19文件大小: (64, 1500, 40, 6)\n",
      "mat20文件大小: (64, 1500, 40, 6)\n",
      "mat21文件大小: (64, 1500, 40, 6)\n",
      "mat22文件大小: (64, 1500, 40, 6)\n",
      "mat23文件大小: (64, 1500, 40, 6)\n",
      "mat24文件大小: (64, 1500, 40, 6)\n",
      "mat25文件大小: (64, 1500, 40, 6)\n",
      "mat26文件大小: (64, 1500, 40, 6)\n",
      "mat27文件大小: (64, 1500, 40, 6)\n",
      "mat28文件大小: (64, 1500, 40, 6)\n",
      "mat29文件大小: (64, 1500, 40, 6)\n",
      "mat30文件大小: (64, 1500, 40, 6)\n",
      "mat31文件大小: (64, 1500, 40, 6)\n",
      "mat32文件大小: (64, 1500, 40, 6)\n",
      "mat33文件大小: (64, 1500, 40, 6)\n",
      "mat34文件大小: (64, 1500, 40, 6)\n",
      "mat35文件大小: (64, 1500, 40, 6)\n"
     ]
    }
   ],
   "source": [
    "# torch.set_default_dtype(torch.float64)\n",
    "train_data = Benchmark(\"E:\\Datasets\\BCI\\SSVEP\\Benchmark\", train = True, \n",
    "                       transform = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ]))\n",
    "test_data = Benchmark(\"E:\\Datasets\\BCI\\SSVEP\\Benchmark\", train = False, \n",
    "                       transform = transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T15:45:14.778425400Z",
     "start_time": "2024-02-25T15:44:36.355254100Z"
    }
   },
   "id": "b2e928e06e622fd7"
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data:\n",
      " 7000\n",
      "shape: torch.Size([1, 9, 1375]), type: <class 'torch.Tensor'>\n",
      "test_data:\n",
      " 1400\n",
      "shape: torch.Size([1, 9, 1375]), type: <class 'torch.Tensor'>\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "print(\"train_data:\\n\", len(train_data))\n",
    "print(f\"shape: {train_data[0][0].shape}, type: {type(train_data[0][0])}\")\n",
    "\n",
    "print(\"test_data:\\n\", len(test_data))\n",
    "print(f\"shape: {test_data[0][0].shape}, type: {type(test_data[0][0])}\")\n",
    "\n",
    "print(train_data[2][1])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T15:45:49.557237600Z",
     "start_time": "2024-02-25T15:45:49.547235100Z"
    }
   },
   "id": "b5a91edee5bf87c4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 二、EEGNet构建"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "74cc6cfc51129a49"
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float64\n",
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda' if not torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "class DepthwiseSeparableConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, depth_multiplier=1):\n",
    "        super(DepthwiseSeparableConv2d, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels * depth_multiplier, kernel_size=kernel_size,\n",
    "                                   stride=(1, 1), padding=(0, 0 if kernel_size[0]>kernel_size[1] else max(kernel_size)//2), groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels * depth_multiplier, out_channels, kernel_size=(1, 1),\n",
    "                                   stride=(1, 1), padding=(0, 0), bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class EEGNet(nn.Module):\n",
    "    def __init__(self, nb_classes, Chans=64, Samples=128, dropoutRate=0.5, kernLength=64,\n",
    "                 F1=8, D=2, F2=16, norm_rate=0.25, dropoutType='Dropout'):\n",
    "        super(EEGNet, self).__init__()\n",
    "\n",
    "        if dropoutType == 'SpatialDropout2D':\n",
    "            self.dropoutType = nn.Dropout2d\n",
    "        elif dropoutType == 'Dropout':\n",
    "            self.dropoutType = nn.Dropout\n",
    "        else:\n",
    "            raise ValueError('dropoutType must be one of SpatialDropout2D '\n",
    "                             'or Dropout, passed as a string.')\n",
    "\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(1, F1, (1, kernLength), padding=(0, kernLength//2), bias=False),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            DepthwiseSeparableConv2d(F1, F1, kernel_size=(Chans, 1), depth_multiplier=D),\n",
    "            nn.BatchNorm2d(F1),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 4)),\n",
    "            self.dropoutType(dropoutRate)\n",
    "        )\n",
    "\n",
    "        self.block2 = nn.Sequential(\n",
    "            DepthwiseSeparableConv2d(F1, F2, kernel_size=(1, 16), depth_multiplier=1),\n",
    "            nn.BatchNorm2d(F2),\n",
    "            nn.ELU(),\n",
    "            nn.AvgPool2d((1, 8)),\n",
    "            self.dropoutType(dropoutRate)\n",
    "        )\n",
    "\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(F2*int(np.floor((np.floor((Samples+1)/4)+1)/8)), nb_classes),\n",
    "            nn.Softmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        x = self.block1(input)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        return x\n",
    "\n",
    "learning_rate = 1e-3\n",
    "nb_classes = 40\n",
    "Chans = 9\n",
    "Samples = 1375\n",
    "model = EEGNet(nb_classes, Chans, Samples)\n",
    "model = model.to(device)\n",
    "# torch.set_default_dtype(torch.float64)\n",
    "print(model.state_dict()['block1.0.weight'].dtype)\n",
    "print(device)\n",
    "# print(summary(model, input_size=(1, 9, 1375), device=\"cuda\"))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T15:45:57.681620900Z",
     "start_time": "2024-02-25T15:45:57.672620800Z"
    }
   },
   "id": "9b344932ffcc584d"
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[81], line 33\u001B[0m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;66;03m# 优化器优化模型\u001B[39;00m\n\u001B[0;32m     32\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m---> 33\u001B[0m \u001B[43moptimizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstep\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     34\u001B[0m \u001B[38;5;66;03m# 误差分析\u001B[39;00m\n\u001B[0;32m     35\u001B[0m total_train_step \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:373\u001B[0m, in \u001B[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001B[1;34m(*args, **kwargs)\u001B[0m\n\u001B[0;32m    368\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    369\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\n\u001B[0;32m    370\u001B[0m                 \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfunc\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mresult\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m    371\u001B[0m             )\n\u001B[1;32m--> 373\u001B[0m out \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    374\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_optimizer_step_code()\n\u001B[0;32m    376\u001B[0m \u001B[38;5;66;03m# call optimizer step post hooks\u001B[39;00m\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:76\u001B[0m, in \u001B[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m     74\u001B[0m     torch\u001B[38;5;241m.\u001B[39mset_grad_enabled(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdefaults[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mdifferentiable\u001B[39m\u001B[38;5;124m'\u001B[39m])\n\u001B[0;32m     75\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n\u001B[1;32m---> 76\u001B[0m     ret \u001B[38;5;241m=\u001B[39m func(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m     77\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m     78\u001B[0m     torch\u001B[38;5;241m.\u001B[39m_dynamo\u001B[38;5;241m.\u001B[39mgraph_break()\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py:138\u001B[0m, in \u001B[0;36mAdam.step\u001B[1;34m(self, closure)\u001B[0m\n\u001B[0;32m    130\u001B[0m \u001B[38;5;129m@_use_grad_for_differentiable\u001B[39m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mstep\u001B[39m(\u001B[38;5;28mself\u001B[39m, closure\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m    132\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Performs a single optimization step.\u001B[39;00m\n\u001B[0;32m    133\u001B[0m \n\u001B[0;32m    134\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        closure (Callable, optional): A closure that reevaluates the model\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m            and returns the loss.\u001B[39;00m\n\u001B[0;32m    137\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 138\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_cuda_graph_capture_health_check\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    140\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    141\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m closure \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py:321\u001B[0m, in \u001B[0;36mOptimizer._cuda_graph_capture_health_check\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    309\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_cuda_graph_capture_health_check\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    310\u001B[0m     \u001B[38;5;66;03m# Note [torch.compile x capturable]\u001B[39;00m\n\u001B[0;32m    311\u001B[0m     \u001B[38;5;66;03m# If we are compiling, we try to take the capturable path automatically by\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    318\u001B[0m     \u001B[38;5;66;03m# Thus, when compiling, inductor will determine if cudagraphs\u001B[39;00m\n\u001B[0;32m    319\u001B[0m     \u001B[38;5;66;03m# can be enabled based on whether there is input mutation or CPU tensors.\u001B[39;00m\n\u001B[0;32m    320\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_compiling() \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mbackends\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_built() \u001B[38;5;129;01mand\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcuda\u001B[38;5;241m.\u001B[39mis_available():\n\u001B[1;32m--> 321\u001B[0m         capturing \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcuda\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mis_current_stream_capturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    323\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m capturing \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mall\u001B[39m(group[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcapturable\u001B[39m\u001B[38;5;124m'\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m group \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mparam_groups):\n\u001B[0;32m    324\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mRuntimeError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mAttempting CUDA graph capture of step() for an instance of \u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m    325\u001B[0m                                \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m+\u001B[39m\n\u001B[0;32m    326\u001B[0m                                \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m but param_groups\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m capturable is False.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[1;32mD:\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\cuda\\graphs.py:32\u001B[0m, in \u001B[0;36mis_current_stream_capturing\u001B[1;34m()\u001B[0m\n\u001B[0;32m     26\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mis_current_stream_capturing\u001B[39m():\n\u001B[0;32m     27\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;124;03m    Returns True if CUDA graph capture is underway on the current CUDA stream, False otherwise.\u001B[39;00m\n\u001B[0;32m     29\u001B[0m \n\u001B[0;32m     30\u001B[0m \u001B[38;5;124;03m    If a CUDA context does not exist on the current device, returns False without initializing the context.\u001B[39;00m\n\u001B[0;32m     31\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m---> 32\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43m_cuda_isCurrentStreamCapturing\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import os\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "# tensorboard 记录训练结果\n",
    "# writer = SummaryWriter(\"./logs_train\")\n",
    "\n",
    "# dataloader\n",
    "train_loader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(test_data, batch_size=16, shuffle=False)\n",
    "\n",
    "# 损失函数\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# 优化器\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, foreach=False)\n",
    "\n",
    "# Training Loop\n",
    "start_time = time.time()\n",
    "total_train_step = 0\n",
    "num_epochs = 200\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for inputs, labels in train_loader:\n",
    "        labels = labels - 1\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # 优化器清除梯度\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        # 交叉熵计算损失\n",
    "        loss = criterion(outputs, labels.long())\n",
    "        # 优化器优化模型\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # 误差分析\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            end_time = time.time()\n",
    "            print(f\"{end_time-start_time}  训练次数：{total_train_step}, Loss：{loss}\")\n",
    "            # writer.add_scalar(\"train_loss\", loss.item(), total_train_step)\n",
    "            \n",
    "# 测试\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    total_correct = 0        \n",
    "    total_samples = 0\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        values, predicted = torch.max(outputs, dim=1)\n",
    "        total_correct += (predicted == labels).sum().item()\n",
    "        total_samples += len(labels)\n",
    "    \n",
    "    accuracy = total_correct / total_samples\n",
    "    print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    torch.save(model, f\".\\Weights/eeg_gpu.pth\")\n",
    "    # torch.save(light.state_dict(), f\"Weights/light_{epoch}.pth\")\n",
    "    print(\"模型已保存\")\n",
    "# writer.close()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-25T15:53:48.284396100Z",
     "start_time": "2024-02-25T15:53:48.186191800Z"
    }
   },
   "id": "4b19576f5a7dabfd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "c2c56d44a0b8c4e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "57e523c0f932d833"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "91ac362022690b1d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d5946e52139ccfb3"
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: torch.Size([16, 1, 9, 1375])\n",
      "1: torch.Size([16, 1, 9, 1375])\n",
      "2: torch.Size([16, 1, 9, 1375])\n",
      "3: torch.Size([16, 1, 9, 1375])\n",
      "4: torch.Size([16, 1, 9, 1375])\n",
      "5: torch.Size([16, 1, 9, 1375])\n",
      "6: torch.Size([16, 1, 9, 1375])\n",
      "7: torch.Size([16, 1, 9, 1375])\n",
      "8: torch.Size([16, 1, 9, 1375])\n",
      "9: torch.Size([16, 1, 9, 1375])\n",
      "10: torch.Size([16, 1, 9, 1375])\n",
      "11: torch.Size([16, 1, 9, 1375])\n",
      "12: torch.Size([16, 1, 9, 1375])\n",
      "13: torch.Size([16, 1, 9, 1375])\n",
      "14: torch.Size([16, 1, 9, 1375])\n",
      "15: torch.Size([16, 1, 9, 1375])\n",
      "16: torch.Size([16, 1, 9, 1375])\n",
      "17: torch.Size([16, 1, 9, 1375])\n",
      "18: torch.Size([16, 1, 9, 1375])\n",
      "19: torch.Size([16, 1, 9, 1375])\n",
      "20: torch.Size([16, 1, 9, 1375])\n",
      "21: torch.Size([16, 1, 9, 1375])\n",
      "22: torch.Size([16, 1, 9, 1375])\n",
      "23: torch.Size([16, 1, 9, 1375])\n",
      "24: torch.Size([16, 1, 9, 1375])\n",
      "25: torch.Size([16, 1, 9, 1375])\n",
      "26: torch.Size([16, 1, 9, 1375])\n",
      "27: torch.Size([16, 1, 9, 1375])\n",
      "28: torch.Size([16, 1, 9, 1375])\n",
      "29: torch.Size([16, 1, 9, 1375])\n",
      "30: torch.Size([16, 1, 9, 1375])\n",
      "31: torch.Size([16, 1, 9, 1375])\n",
      "32: torch.Size([16, 1, 9, 1375])\n",
      "33: torch.Size([16, 1, 9, 1375])\n",
      "34: torch.Size([16, 1, 9, 1375])\n",
      "35: torch.Size([16, 1, 9, 1375])\n",
      "36: torch.Size([16, 1, 9, 1375])\n",
      "37: torch.Size([16, 1, 9, 1375])\n",
      "38: torch.Size([16, 1, 9, 1375])\n",
      "39: torch.Size([16, 1, 9, 1375])\n",
      "40: torch.Size([16, 1, 9, 1375])\n",
      "41: torch.Size([16, 1, 9, 1375])\n",
      "42: torch.Size([16, 1, 9, 1375])\n",
      "43: torch.Size([16, 1, 9, 1375])\n",
      "44: torch.Size([16, 1, 9, 1375])\n",
      "45: torch.Size([16, 1, 9, 1375])\n",
      "46: torch.Size([16, 1, 9, 1375])\n",
      "47: torch.Size([16, 1, 9, 1375])\n",
      "48: torch.Size([16, 1, 9, 1375])\n",
      "49: torch.Size([16, 1, 9, 1375])\n",
      "50: torch.Size([16, 1, 9, 1375])\n",
      "51: torch.Size([16, 1, 9, 1375])\n",
      "52: torch.Size([16, 1, 9, 1375])\n",
      "53: torch.Size([16, 1, 9, 1375])\n",
      "54: torch.Size([16, 1, 9, 1375])\n",
      "55: torch.Size([16, 1, 9, 1375])\n",
      "56: torch.Size([16, 1, 9, 1375])\n",
      "57: torch.Size([16, 1, 9, 1375])\n",
      "58: torch.Size([16, 1, 9, 1375])\n",
      "59: torch.Size([16, 1, 9, 1375])\n",
      "60: torch.Size([16, 1, 9, 1375])\n",
      "61: torch.Size([16, 1, 9, 1375])\n",
      "62: torch.Size([16, 1, 9, 1375])\n",
      "63: torch.Size([16, 1, 9, 1375])\n",
      "64: torch.Size([16, 1, 9, 1375])\n",
      "65: torch.Size([16, 1, 9, 1375])\n",
      "66: torch.Size([16, 1, 9, 1375])\n",
      "67: torch.Size([16, 1, 9, 1375])\n",
      "68: torch.Size([16, 1, 9, 1375])\n",
      "69: torch.Size([16, 1, 9, 1375])\n",
      "70: torch.Size([16, 1, 9, 1375])\n",
      "71: torch.Size([16, 1, 9, 1375])\n",
      "72: torch.Size([16, 1, 9, 1375])\n",
      "73: torch.Size([16, 1, 9, 1375])\n",
      "74: torch.Size([16, 1, 9, 1375])\n",
      "75: torch.Size([16, 1, 9, 1375])\n",
      "76: torch.Size([16, 1, 9, 1375])\n",
      "77: torch.Size([16, 1, 9, 1375])\n",
      "78: torch.Size([16, 1, 9, 1375])\n",
      "79: torch.Size([16, 1, 9, 1375])\n",
      "80: torch.Size([16, 1, 9, 1375])\n",
      "81: torch.Size([16, 1, 9, 1375])\n",
      "82: torch.Size([16, 1, 9, 1375])\n",
      "83: torch.Size([16, 1, 9, 1375])\n",
      "84: torch.Size([16, 1, 9, 1375])\n",
      "85: torch.Size([16, 1, 9, 1375])\n",
      "86: torch.Size([16, 1, 9, 1375])\n",
      "87: torch.Size([16, 1, 9, 1375])\n",
      "88: torch.Size([16, 1, 9, 1375])\n",
      "89: torch.Size([16, 1, 9, 1375])\n",
      "90: torch.Size([16, 1, 9, 1375])\n",
      "91: torch.Size([16, 1, 9, 1375])\n",
      "92: torch.Size([16, 1, 9, 1375])\n",
      "93: torch.Size([16, 1, 9, 1375])\n",
      "94: torch.Size([16, 1, 9, 1375])\n",
      "95: torch.Size([16, 1, 9, 1375])\n",
      "96: torch.Size([16, 1, 9, 1375])\n",
      "97: torch.Size([16, 1, 9, 1375])\n",
      "98: torch.Size([16, 1, 9, 1375])\n",
      "99: torch.Size([16, 1, 9, 1375])\n",
      "100: torch.Size([16, 1, 9, 1375])\n",
      "101: torch.Size([16, 1, 9, 1375])\n",
      "102: torch.Size([16, 1, 9, 1375])\n",
      "103: torch.Size([16, 1, 9, 1375])\n",
      "104: torch.Size([16, 1, 9, 1375])\n",
      "105: torch.Size([16, 1, 9, 1375])\n",
      "106: torch.Size([16, 1, 9, 1375])\n",
      "107: torch.Size([16, 1, 9, 1375])\n",
      "108: torch.Size([16, 1, 9, 1375])\n",
      "109: torch.Size([16, 1, 9, 1375])\n",
      "110: torch.Size([16, 1, 9, 1375])\n",
      "111: torch.Size([16, 1, 9, 1375])\n",
      "112: torch.Size([16, 1, 9, 1375])\n",
      "113: torch.Size([16, 1, 9, 1375])\n",
      "114: torch.Size([16, 1, 9, 1375])\n",
      "115: torch.Size([16, 1, 9, 1375])\n",
      "116: torch.Size([16, 1, 9, 1375])\n",
      "117: torch.Size([16, 1, 9, 1375])\n",
      "118: torch.Size([16, 1, 9, 1375])\n",
      "119: torch.Size([16, 1, 9, 1375])\n",
      "120: torch.Size([16, 1, 9, 1375])\n",
      "121: torch.Size([16, 1, 9, 1375])\n",
      "122: torch.Size([16, 1, 9, 1375])\n",
      "123: torch.Size([16, 1, 9, 1375])\n",
      "124: torch.Size([16, 1, 9, 1375])\n",
      "125: torch.Size([16, 1, 9, 1375])\n",
      "126: torch.Size([16, 1, 9, 1375])\n",
      "127: torch.Size([16, 1, 9, 1375])\n",
      "128: torch.Size([16, 1, 9, 1375])\n",
      "129: torch.Size([16, 1, 9, 1375])\n",
      "130: torch.Size([16, 1, 9, 1375])\n",
      "131: torch.Size([16, 1, 9, 1375])\n",
      "132: torch.Size([16, 1, 9, 1375])\n",
      "133: torch.Size([16, 1, 9, 1375])\n",
      "134: torch.Size([16, 1, 9, 1375])\n",
      "135: torch.Size([16, 1, 9, 1375])\n",
      "136: torch.Size([16, 1, 9, 1375])\n",
      "137: torch.Size([16, 1, 9, 1375])\n",
      "138: torch.Size([16, 1, 9, 1375])\n",
      "139: torch.Size([16, 1, 9, 1375])\n",
      "140: torch.Size([16, 1, 9, 1375])\n",
      "141: torch.Size([16, 1, 9, 1375])\n",
      "142: torch.Size([16, 1, 9, 1375])\n",
      "143: torch.Size([16, 1, 9, 1375])\n",
      "144: torch.Size([16, 1, 9, 1375])\n",
      "145: torch.Size([16, 1, 9, 1375])\n",
      "146: torch.Size([16, 1, 9, 1375])\n",
      "147: torch.Size([16, 1, 9, 1375])\n",
      "148: torch.Size([16, 1, 9, 1375])\n",
      "149: torch.Size([16, 1, 9, 1375])\n",
      "150: torch.Size([16, 1, 9, 1375])\n",
      "151: torch.Size([16, 1, 9, 1375])\n",
      "152: torch.Size([16, 1, 9, 1375])\n",
      "153: torch.Size([16, 1, 9, 1375])\n",
      "154: torch.Size([16, 1, 9, 1375])\n",
      "155: torch.Size([16, 1, 9, 1375])\n",
      "156: torch.Size([16, 1, 9, 1375])\n",
      "157: torch.Size([16, 1, 9, 1375])\n",
      "158: torch.Size([16, 1, 9, 1375])\n",
      "159: torch.Size([16, 1, 9, 1375])\n",
      "160: torch.Size([16, 1, 9, 1375])\n",
      "161: torch.Size([16, 1, 9, 1375])\n",
      "162: torch.Size([16, 1, 9, 1375])\n",
      "163: torch.Size([16, 1, 9, 1375])\n",
      "164: torch.Size([16, 1, 9, 1375])\n",
      "165: torch.Size([16, 1, 9, 1375])\n",
      "166: torch.Size([16, 1, 9, 1375])\n",
      "167: torch.Size([16, 1, 9, 1375])\n",
      "168: torch.Size([16, 1, 9, 1375])\n",
      "169: torch.Size([16, 1, 9, 1375])\n",
      "170: torch.Size([16, 1, 9, 1375])\n",
      "171: torch.Size([16, 1, 9, 1375])\n",
      "172: torch.Size([16, 1, 9, 1375])\n",
      "173: torch.Size([16, 1, 9, 1375])\n",
      "174: torch.Size([16, 1, 9, 1375])\n",
      "175: torch.Size([16, 1, 9, 1375])\n",
      "176: torch.Size([16, 1, 9, 1375])\n",
      "177: torch.Size([16, 1, 9, 1375])\n",
      "178: torch.Size([16, 1, 9, 1375])\n",
      "179: torch.Size([16, 1, 9, 1375])\n",
      "180: torch.Size([16, 1, 9, 1375])\n",
      "181: torch.Size([16, 1, 9, 1375])\n",
      "182: torch.Size([16, 1, 9, 1375])\n",
      "183: torch.Size([16, 1, 9, 1375])\n",
      "184: torch.Size([16, 1, 9, 1375])\n",
      "185: torch.Size([16, 1, 9, 1375])\n",
      "186: torch.Size([16, 1, 9, 1375])\n",
      "187: torch.Size([16, 1, 9, 1375])\n",
      "188: torch.Size([16, 1, 9, 1375])\n",
      "189: torch.Size([16, 1, 9, 1375])\n",
      "190: torch.Size([16, 1, 9, 1375])\n",
      "191: torch.Size([16, 1, 9, 1375])\n",
      "192: torch.Size([16, 1, 9, 1375])\n",
      "193: torch.Size([16, 1, 9, 1375])\n",
      "194: torch.Size([16, 1, 9, 1375])\n",
      "195: torch.Size([16, 1, 9, 1375])\n",
      "196: torch.Size([16, 1, 9, 1375])\n",
      "197: torch.Size([16, 1, 9, 1375])\n",
      "198: torch.Size([16, 1, 9, 1375])\n",
      "199: torch.Size([16, 1, 9, 1375])\n",
      "200: torch.Size([16, 1, 9, 1375])\n",
      "201: torch.Size([16, 1, 9, 1375])\n",
      "202: torch.Size([16, 1, 9, 1375])\n",
      "203: torch.Size([16, 1, 9, 1375])\n",
      "204: torch.Size([16, 1, 9, 1375])\n",
      "205: torch.Size([16, 1, 9, 1375])\n",
      "206: torch.Size([16, 1, 9, 1375])\n",
      "207: torch.Size([16, 1, 9, 1375])\n",
      "208: torch.Size([16, 1, 9, 1375])\n",
      "209: torch.Size([16, 1, 9, 1375])\n",
      "210: torch.Size([16, 1, 9, 1375])\n",
      "211: torch.Size([16, 1, 9, 1375])\n",
      "212: torch.Size([16, 1, 9, 1375])\n",
      "213: torch.Size([16, 1, 9, 1375])\n",
      "214: torch.Size([16, 1, 9, 1375])\n",
      "215: torch.Size([16, 1, 9, 1375])\n",
      "216: torch.Size([16, 1, 9, 1375])\n",
      "217: torch.Size([16, 1, 9, 1375])\n",
      "218: torch.Size([16, 1, 9, 1375])\n",
      "219: torch.Size([16, 1, 9, 1375])\n",
      "220: torch.Size([16, 1, 9, 1375])\n",
      "221: torch.Size([16, 1, 9, 1375])\n",
      "222: torch.Size([16, 1, 9, 1375])\n",
      "223: torch.Size([16, 1, 9, 1375])\n",
      "224: torch.Size([16, 1, 9, 1375])\n",
      "225: torch.Size([16, 1, 9, 1375])\n",
      "226: torch.Size([16, 1, 9, 1375])\n",
      "227: torch.Size([16, 1, 9, 1375])\n",
      "228: torch.Size([16, 1, 9, 1375])\n",
      "229: torch.Size([16, 1, 9, 1375])\n",
      "230: torch.Size([16, 1, 9, 1375])\n",
      "231: torch.Size([16, 1, 9, 1375])\n",
      "232: torch.Size([16, 1, 9, 1375])\n",
      "233: torch.Size([16, 1, 9, 1375])\n",
      "234: torch.Size([16, 1, 9, 1375])\n",
      "235: torch.Size([16, 1, 9, 1375])\n",
      "236: torch.Size([16, 1, 9, 1375])\n",
      "237: torch.Size([16, 1, 9, 1375])\n",
      "238: torch.Size([16, 1, 9, 1375])\n",
      "239: torch.Size([16, 1, 9, 1375])\n",
      "240: torch.Size([16, 1, 9, 1375])\n",
      "241: torch.Size([16, 1, 9, 1375])\n",
      "242: torch.Size([16, 1, 9, 1375])\n",
      "243: torch.Size([16, 1, 9, 1375])\n",
      "244: torch.Size([16, 1, 9, 1375])\n",
      "245: torch.Size([16, 1, 9, 1375])\n",
      "246: torch.Size([16, 1, 9, 1375])\n",
      "247: torch.Size([16, 1, 9, 1375])\n",
      "248: torch.Size([16, 1, 9, 1375])\n",
      "249: torch.Size([16, 1, 9, 1375])\n",
      "250: torch.Size([16, 1, 9, 1375])\n",
      "251: torch.Size([16, 1, 9, 1375])\n",
      "252: torch.Size([16, 1, 9, 1375])\n",
      "253: torch.Size([16, 1, 9, 1375])\n",
      "254: torch.Size([16, 1, 9, 1375])\n",
      "255: torch.Size([16, 1, 9, 1375])\n",
      "256: torch.Size([16, 1, 9, 1375])\n",
      "257: torch.Size([16, 1, 9, 1375])\n",
      "258: torch.Size([16, 1, 9, 1375])\n",
      "259: torch.Size([16, 1, 9, 1375])\n",
      "260: torch.Size([16, 1, 9, 1375])\n",
      "261: torch.Size([16, 1, 9, 1375])\n",
      "262: torch.Size([16, 1, 9, 1375])\n",
      "263: torch.Size([16, 1, 9, 1375])\n",
      "264: torch.Size([16, 1, 9, 1375])\n",
      "265: torch.Size([16, 1, 9, 1375])\n",
      "266: torch.Size([16, 1, 9, 1375])\n",
      "267: torch.Size([16, 1, 9, 1375])\n",
      "268: torch.Size([16, 1, 9, 1375])\n",
      "269: torch.Size([16, 1, 9, 1375])\n",
      "270: torch.Size([16, 1, 9, 1375])\n",
      "271: torch.Size([16, 1, 9, 1375])\n",
      "272: torch.Size([16, 1, 9, 1375])\n",
      "273: torch.Size([16, 1, 9, 1375])\n",
      "274: torch.Size([16, 1, 9, 1375])\n",
      "275: torch.Size([16, 1, 9, 1375])\n",
      "276: torch.Size([16, 1, 9, 1375])\n",
      "277: torch.Size([16, 1, 9, 1375])\n",
      "278: torch.Size([16, 1, 9, 1375])\n",
      "279: torch.Size([16, 1, 9, 1375])\n",
      "280: torch.Size([16, 1, 9, 1375])\n",
      "281: torch.Size([16, 1, 9, 1375])\n",
      "282: torch.Size([16, 1, 9, 1375])\n",
      "283: torch.Size([16, 1, 9, 1375])\n",
      "284: torch.Size([16, 1, 9, 1375])\n",
      "285: torch.Size([16, 1, 9, 1375])\n",
      "286: torch.Size([16, 1, 9, 1375])\n",
      "287: torch.Size([16, 1, 9, 1375])\n",
      "288: torch.Size([16, 1, 9, 1375])\n",
      "289: torch.Size([16, 1, 9, 1375])\n",
      "290: torch.Size([16, 1, 9, 1375])\n",
      "291: torch.Size([16, 1, 9, 1375])\n",
      "292: torch.Size([16, 1, 9, 1375])\n",
      "293: torch.Size([16, 1, 9, 1375])\n",
      "294: torch.Size([16, 1, 9, 1375])\n",
      "295: torch.Size([16, 1, 9, 1375])\n",
      "296: torch.Size([16, 1, 9, 1375])\n",
      "297: torch.Size([16, 1, 9, 1375])\n",
      "298: torch.Size([16, 1, 9, 1375])\n",
      "299: torch.Size([16, 1, 9, 1375])\n",
      "300: torch.Size([16, 1, 9, 1375])\n",
      "301: torch.Size([16, 1, 9, 1375])\n",
      "302: torch.Size([16, 1, 9, 1375])\n",
      "303: torch.Size([16, 1, 9, 1375])\n",
      "304: torch.Size([16, 1, 9, 1375])\n",
      "305: torch.Size([16, 1, 9, 1375])\n",
      "306: torch.Size([16, 1, 9, 1375])\n",
      "307: torch.Size([16, 1, 9, 1375])\n",
      "308: torch.Size([16, 1, 9, 1375])\n",
      "309: torch.Size([16, 1, 9, 1375])\n",
      "310: torch.Size([16, 1, 9, 1375])\n",
      "311: torch.Size([16, 1, 9, 1375])\n",
      "312: torch.Size([16, 1, 9, 1375])\n",
      "313: torch.Size([16, 1, 9, 1375])\n",
      "314: torch.Size([16, 1, 9, 1375])\n",
      "315: torch.Size([16, 1, 9, 1375])\n",
      "316: torch.Size([16, 1, 9, 1375])\n",
      "317: torch.Size([16, 1, 9, 1375])\n",
      "318: torch.Size([16, 1, 9, 1375])\n",
      "319: torch.Size([16, 1, 9, 1375])\n",
      "320: torch.Size([16, 1, 9, 1375])\n",
      "321: torch.Size([16, 1, 9, 1375])\n",
      "322: torch.Size([16, 1, 9, 1375])\n",
      "323: torch.Size([16, 1, 9, 1375])\n",
      "324: torch.Size([16, 1, 9, 1375])\n",
      "325: torch.Size([16, 1, 9, 1375])\n",
      "326: torch.Size([16, 1, 9, 1375])\n",
      "327: torch.Size([16, 1, 9, 1375])\n",
      "328: torch.Size([16, 1, 9, 1375])\n",
      "329: torch.Size([16, 1, 9, 1375])\n",
      "330: torch.Size([16, 1, 9, 1375])\n",
      "331: torch.Size([16, 1, 9, 1375])\n",
      "332: torch.Size([16, 1, 9, 1375])\n",
      "333: torch.Size([16, 1, 9, 1375])\n",
      "334: torch.Size([16, 1, 9, 1375])\n",
      "335: torch.Size([16, 1, 9, 1375])\n",
      "336: torch.Size([16, 1, 9, 1375])\n",
      "337: torch.Size([16, 1, 9, 1375])\n",
      "338: torch.Size([16, 1, 9, 1375])\n",
      "339: torch.Size([16, 1, 9, 1375])\n",
      "340: torch.Size([16, 1, 9, 1375])\n",
      "341: torch.Size([16, 1, 9, 1375])\n",
      "342: torch.Size([16, 1, 9, 1375])\n",
      "343: torch.Size([16, 1, 9, 1375])\n",
      "344: torch.Size([16, 1, 9, 1375])\n",
      "345: torch.Size([16, 1, 9, 1375])\n",
      "346: torch.Size([16, 1, 9, 1375])\n",
      "347: torch.Size([16, 1, 9, 1375])\n",
      "348: torch.Size([16, 1, 9, 1375])\n",
      "349: torch.Size([16, 1, 9, 1375])\n",
      "350: torch.Size([16, 1, 9, 1375])\n",
      "351: torch.Size([16, 1, 9, 1375])\n",
      "352: torch.Size([16, 1, 9, 1375])\n",
      "353: torch.Size([16, 1, 9, 1375])\n",
      "354: torch.Size([16, 1, 9, 1375])\n",
      "355: torch.Size([16, 1, 9, 1375])\n",
      "356: torch.Size([16, 1, 9, 1375])\n",
      "357: torch.Size([16, 1, 9, 1375])\n",
      "358: torch.Size([16, 1, 9, 1375])\n",
      "359: torch.Size([16, 1, 9, 1375])\n",
      "360: torch.Size([16, 1, 9, 1375])\n",
      "361: torch.Size([16, 1, 9, 1375])\n",
      "362: torch.Size([16, 1, 9, 1375])\n",
      "363: torch.Size([16, 1, 9, 1375])\n",
      "364: torch.Size([16, 1, 9, 1375])\n",
      "365: torch.Size([16, 1, 9, 1375])\n",
      "366: torch.Size([16, 1, 9, 1375])\n",
      "367: torch.Size([16, 1, 9, 1375])\n",
      "368: torch.Size([16, 1, 9, 1375])\n",
      "369: torch.Size([16, 1, 9, 1375])\n",
      "370: torch.Size([16, 1, 9, 1375])\n",
      "371: torch.Size([16, 1, 9, 1375])\n",
      "372: torch.Size([16, 1, 9, 1375])\n",
      "373: torch.Size([16, 1, 9, 1375])\n",
      "374: torch.Size([16, 1, 9, 1375])\n",
      "375: torch.Size([16, 1, 9, 1375])\n",
      "376: torch.Size([16, 1, 9, 1375])\n",
      "377: torch.Size([16, 1, 9, 1375])\n",
      "378: torch.Size([16, 1, 9, 1375])\n",
      "379: torch.Size([16, 1, 9, 1375])\n",
      "380: torch.Size([16, 1, 9, 1375])\n",
      "381: torch.Size([16, 1, 9, 1375])\n",
      "382: torch.Size([16, 1, 9, 1375])\n",
      "383: torch.Size([16, 1, 9, 1375])\n",
      "384: torch.Size([16, 1, 9, 1375])\n",
      "385: torch.Size([16, 1, 9, 1375])\n",
      "386: torch.Size([16, 1, 9, 1375])\n",
      "387: torch.Size([16, 1, 9, 1375])\n",
      "388: torch.Size([16, 1, 9, 1375])\n",
      "389: torch.Size([16, 1, 9, 1375])\n",
      "390: torch.Size([16, 1, 9, 1375])\n",
      "391: torch.Size([16, 1, 9, 1375])\n",
      "392: torch.Size([16, 1, 9, 1375])\n",
      "393: torch.Size([16, 1, 9, 1375])\n",
      "394: torch.Size([16, 1, 9, 1375])\n",
      "395: torch.Size([16, 1, 9, 1375])\n",
      "396: torch.Size([16, 1, 9, 1375])\n",
      "397: torch.Size([16, 1, 9, 1375])\n",
      "398: torch.Size([16, 1, 9, 1375])\n",
      "399: torch.Size([16, 1, 9, 1375])\n",
      "400: torch.Size([16, 1, 9, 1375])\n",
      "401: torch.Size([16, 1, 9, 1375])\n",
      "402: torch.Size([16, 1, 9, 1375])\n",
      "403: torch.Size([16, 1, 9, 1375])\n",
      "404: torch.Size([16, 1, 9, 1375])\n",
      "405: torch.Size([16, 1, 9, 1375])\n",
      "406: torch.Size([16, 1, 9, 1375])\n",
      "407: torch.Size([16, 1, 9, 1375])\n",
      "408: torch.Size([16, 1, 9, 1375])\n",
      "409: torch.Size([16, 1, 9, 1375])\n",
      "410: torch.Size([16, 1, 9, 1375])\n",
      "411: torch.Size([16, 1, 9, 1375])\n",
      "412: torch.Size([16, 1, 9, 1375])\n",
      "413: torch.Size([16, 1, 9, 1375])\n",
      "414: torch.Size([16, 1, 9, 1375])\n",
      "415: torch.Size([16, 1, 9, 1375])\n",
      "416: torch.Size([16, 1, 9, 1375])\n",
      "417: torch.Size([16, 1, 9, 1375])\n",
      "418: torch.Size([16, 1, 9, 1375])\n",
      "419: torch.Size([16, 1, 9, 1375])\n",
      "420: torch.Size([16, 1, 9, 1375])\n",
      "421: torch.Size([16, 1, 9, 1375])\n",
      "422: torch.Size([16, 1, 9, 1375])\n",
      "423: torch.Size([16, 1, 9, 1375])\n",
      "424: torch.Size([16, 1, 9, 1375])\n",
      "425: torch.Size([16, 1, 9, 1375])\n",
      "426: torch.Size([16, 1, 9, 1375])\n",
      "427: torch.Size([16, 1, 9, 1375])\n",
      "428: torch.Size([16, 1, 9, 1375])\n",
      "429: torch.Size([16, 1, 9, 1375])\n",
      "430: torch.Size([16, 1, 9, 1375])\n",
      "431: torch.Size([16, 1, 9, 1375])\n",
      "432: torch.Size([16, 1, 9, 1375])\n",
      "433: torch.Size([16, 1, 9, 1375])\n",
      "434: torch.Size([16, 1, 9, 1375])\n",
      "435: torch.Size([16, 1, 9, 1375])\n",
      "436: torch.Size([16, 1, 9, 1375])\n",
      "437: torch.Size([8, 1, 9, 1375])\n"
     ]
    }
   ],
   "source": [
    "# dataloader = DataLoader(train_data, batch_size=16, shuffle=True)\n",
    "# for i, (eegs, labels) in enumerate(dataloader):\n",
    "#     print(f\"{i}:\", eegs.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T05:29:04.120996800Z",
     "start_time": "2024-02-23T05:29:03.836879900Z"
    }
   },
   "id": "4c916b19155f4de5"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 8.   8.2  8.4  8.6  8.8  9.   9.2  9.4  9.6  9.8 10.  10.2 10.4 10.6\n",
      " 10.8 11.  11.2 11.4 11.6 11.8 12.  12.2 12.4 12.6 12.8 13.  13.2 13.4\n",
      " 13.6 13.8 14.  14.2 14.4 14.6 14.8 15.  15.2 15.4 15.6 15.8]\n"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T05:14:22.537915Z",
     "start_time": "2024-02-23T05:14:22.512069100Z"
    }
   },
   "id": "8841b54738ec7e1e"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-23T05:13:53.775468700Z",
     "start_time": "2024-02-23T05:13:53.435049400Z"
    }
   },
   "id": "b56da2a0a2baa4a5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5a7e143b42e9a015"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "pytorch",
   "language": "python",
   "display_name": "Python Torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
